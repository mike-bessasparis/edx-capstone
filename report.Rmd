---
title: "Report"
output: html_notebook
---

```{r}

library(tidyverse)
library(readr)
library(ggthemes)
library(gridExtra)
library(kableExtra)
library(corrplot)
library(lubridate)
library(caret)


edx <- readRDS(file = "./rda/full_edx.rds")
validation <- readRDS (file = "./rda/full_Validation.rds")

#edx <- readRDS(file = "./rda/full_edx.rds")
#validation <- readRDS (file = "./rda/full_Validation.rds")

```

***
# Explore variables
```{r}

summary(edx)

head(edx)

```

## Response Variable: Rating
```{r}

summary(edx$rating)

```

```{r}

edx %>% ggplot(aes(x=rating)) +
  geom_histogram(binwidth = .5, col="grey") +
  scale_x_continuous(breaks = seq(0, 5, .5)) +
  labs(title = "Notice fewer 1/2 Stars")
  theme_economist_white()



```
## Other interesting variables
```{r}

#Find number of unique movies rated, number of unique users, and number of movies in each genre.

mjb1 <- length(unique(edx$movieId))
mjb2 <- length(unique(edx$userId))

mjb3 <- edx %>% separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(count = n()) %>% 
  arrange(-count)

mjb4 <- nrow(mjb3)

```
In the dataset there are: 

- `r mjb2` unique users
- `r mjb1` unique movies rated
- `r mjb4` unique movie genres

Movies grouped by genre.  Note that a movie may be tagged with several genres, e.g., the movie "Boomerang" is classified as both a "Comedy" and a "Romance."
```{r}

mjb3 %>% ggplot() +
  geom_col(aes(x = reorder(genres, -count), y = count)) +
  coord_flip() +
  xlab("Genre") +
  ylab("Number of Movies") +
  theme_economist_white() +
  theme(axis.text.y.left = element_text(hjust = 1),
        panel.grid.major = element_blank(),
        axis.ticks.y.left = element_line(),
        axis.ticks.x.bottom = element_blank())

```

```{r}

edx %>% filter(genres == "(no genres listed)")

```


What are the top 10 most reviewed movies?
```{r}

edx %>% 
  group_by(title) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  top_n(10)

```
Who are the top 10 active reviewers?
```{r}

edx %>% 
  group_by(userId) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  top_n(10)

```
***
# Relationships (part 1)
## Numeric Correlations with Rating
No continuous numeric predictors to correlate with Rating; userId and movieId are discrete while timestamp is a date.

*** 
# Missing data, label encoding, and factorizing variables
```{r}
#
# make a copy of the data to modify so I don't have to rebuild if something goes bad.
#
edx2 <- edx

#
# First of all, I would like to see which variables contain missing values.
#
NAcol <- which(colSums(is.na(edx2)) > 0)

```

There are `r length(NAcol)` columns with at least one NA.

```{r}

# Label encoding
# There are no labels that are ordinal and should be encoded as a number.

#
# Factorizing variables
#
# edx2 <- edx2 %>% 
#   mutate(rating = factor(rating))

edx2 <- edx2 %>% 
  separate_rows(genres, sep = "\\|") %>% 
  mutate(genres = factor(genres))

edx2 %>% filter(genres == "(no genres listed)")
# "Pull My Daisy (1958)" by Kerouac
# IMDB lists the genre as "Short"


```

***
# Relationships (part 2)
```{r}

#genre and rating
edx2 %>% 
  group_by(genres) %>% 
  summarise(avg_rating = mean(rating))%>% 
  arrange(-avg_rating) %>% 
  ggplot() +
    geom_point(aes(y = reorder(genres, -avg_rating), x = avg_rating)) +
    xlim(0, 5)

# do users have extreme views of each genre
user_genre_affinity <- edx2 %>% 
  group_by(userId, genres) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  filter(avg_rating < 1 | avg_rating > 4.75)

user_genre_affinity %>% ggplot() +
    geom_raster(aes(y = genres, x = userId, fill = avg_rating)) +
    scale_fill_distiller(palette = "Spectral")


```

Average rating of each user.  Red represents a user who rated all movies the same (sd == 0).
```{r}
# user and rating
mjb1 <- edx %>% 
  group_by(userId) %>% 
  summarise(avg_rating = mean(rating), std_dev = sd(rating))%>% 
  arrange(-avg_rating)

outliers <- mjb1 %>% 
  filter(std_dev == 0)

ggplot() +
  geom_point(data = mjb1, aes(x = userId, y = avg_rating), color = "grey") +
  geom_point(data = outliers, aes(x = userId, y = avg_rating), color = "red")  

```
Let's look at the ratings of only these users
```{r}

edx %>%
  filter(userId %in% outliers$userId) %>% 
  ggplot() +
    geom_point(aes(x = as.factor(reorder(userId, rating)), y = rating))

```

How do ratings change over time?
```{r}

#
# make a copy of the data to modify so I don't have to rebuild if something goes bad.
#
edx2 <- edx %>% 
  mutate(timestamp = as_datetime(timestamp))

edx2 %>% 
  filter(timestamp > ymd("2002-01-01") & 
         timestamp < ymd("2004-01-01")) %>% 
  ggplot(aes(x = timestamp, y = rating)) +
    geom_point() +
    labs(title = "1/2 star ratings start in 2003")

edx2 %>% 
  mutate(time_bin = round_date(timestamp, unit = "month")) %>% 
  group_by(time_bin) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  ggplot(aes(x = time_bin, y = avg_rating)) +
    geom_point() +
    geom_smooth(se = FALSE) +
    labs(title = "Monthly average movie rating changes over time.") +
    theme_economist_white()  

```


# Models

```{r}
# library(caret)
# library(tidyverse)
# 
#
# Setup large dataset
#
# edx <- readRDS(file = "./rda/edx.rds")
# set.seed(1)
# test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
# train <- edx[-test_index,]
# temp <- edx[test_index,]
# 
# 
# # Make sure userId and movieId in validation set are also in train set
# validation <- temp %>%
#   semi_join(train, by = "movieId") %>%
#   semi_join(train, by = "userId")
#  
# # Add rows removed from validation set back into edx set
# removed <- anti_join(temp, validation)
# train <- rbind(train, removed)
# 
# # Learners will develop their algorithms on the edx set
# # For grading, learners will run algorithm on validation set to generate ratings
# # validation <- validation %>% select(-rating)
# 
# rm(test_index, temp, removed, edx, small_edx)

#
# save small datasets in order to get them from home PC
#
#write.csv(train, file="train.csv")
#write.csv(validation, file="validation.csv")
#train <- read.csv("train.csv") %>% select(userId, movieId, rating, timestamp, title, genres)
#validation <- read.csv("validation.csv") %>% select(userId, movieId, rating, timestamp, title, genres)

```


IBCF
```{r}
library(caret)
library(tidyverse)
library(recommenderlab)

# can't afford to run on entire dataset.  just use the top X rated movies.
temp <- edx %>% 
  group_by(movieId) %>% 
  summarise(count = n()) %>% 
  top_n(1000, wt = count) %>% 
  arrange(-count) %>% 
  mutate(running_total = cumsum(count))

# reduce the size of the file to train
train_set <- edx %>%
  filter(movieId %in% temp$movieId)
rm(temp)

test_set <- validation

r <- as(train_set, "realRatingMatrix")

rec.model <- Recommender(data = r,
                        method = "IBCF",
                        parameter = list(method = "Cosine"))

saveRDS(rec.model, file = "./rda/top1000_IBCF_model.rds")

# predict movie ratings only from userId in the test_set
# save time by not completing the entire pred matrix
# only if not using the top_n method
#test_set_users <- as.character(unique(test_set$userId))
#pred <- predict(rec.model, r[test_set_users], type = "ratings")

pred <- predict(rec.model, r, type = "ratings")
pred_matrix <- as(pred, "matrix")
saveRDS(pred_matrix, file = "./rda/top1000_IBCF_pred_matrix.rds")

# make into a df
ibcf_preds <- as(pred, "matrix") %>% 
  as.data.frame.matrix() %>% 
  rownames_to_column(var = "userId") %>% 
  gather(key = movieId, value = rating, -userId)

round_rating <- function(pred) {
  pred <- round(pred / 0.5) * 0.5
  return(pred)
}

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")
ibcf_preds <- ibcf_preds %>% 
    mutate(pred_rating = factor(round_rating(rating), levels = rating_levels)) %>% 
    select(-rating)

# 
# Create confusion matrix
#
# factorize test_set ratings
rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")
test_set <- test_set %>% 
  mutate(rating = factor(rating, levels = rating_levels),
         userId = as.character(userId),
         movieId = as.character(movieId)) %>% 
  select(userId, movieId, rating)

v <- left_join(test_set, ibcf_preds)

confusionMatrix(v$pred_rating, v$rating)


```









RecommenderLab - UBCF
```{r}
library(recommenderlab)
library(tidyverse)
library(caret)

round_rating <- function(pred) {
  
  pred <- round(pred/0.5)*0.5
  
  return(pred)

}

train_set <- edx
test_set <- validation

train.matrix <- as(train_set, "realRatingMatrix")

target_users <- as.character(unique(test_set$userId))
#target_users <- as.character(c(18, 54, 56))

# Creation of the model
Rec.model <- Recommender(train.matrix, method = "UBCF")

q <- predict(Rec.model, train.matrix[target_users], type = "ratings")

# convert from matrix to df to make joins easier
ubcf_preds <- as(q, "matrix") %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "userId") %>% 
  gather(key = movieId, value = rating, -userId)

# Create confusion matrix
rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")
ubcf_preds <- ubcf_preds %>% 
    mutate(pred_rating = factor(round_rating(rating), levels = rating_levels)) %>% 
    select(-rating)

test_set <- test_set %>% 
  mutate(rating = factor(rating, levels = rating_levels),
         userId = as.character(userId),
         movieId = as.character(movieId))

test_set2 <- test_set %>% 
  left_join(ubcf_preds)

confusionMatrix(test_set2$rating, test_set2$pred_rating)

```

RecommenderLab - IBCF
```{r}
library(recommenderlab)
library(tidyverse)

mjb <- edx

set.seed(1)
#train_set <- sample_n(mjb, 10000)

affinity.matrix<- as(train_set,"realRatingMatrix")

# Creation of the model
Rec.model.IBCF <- Recommender(affinity.matrix, method = "IBCF")
#parameter = list(k = 3)

q <- predict(Rec.model.IBCF, affinity.matrix[1:50], type = "ratings")
mjb <- as(q, "matrix")

# convert from matrix to df to make joins easier
ibcf_preds <- as(q, "matrix") %>%
  as.data.frame() %>%
  rownames_to_column(var = "userId") %>%
  gather(key = movieId, value = rating, -userId)

```



```{r}

library(caret)
library(tidyverse)
library(lubridate)

train_set <- edx
test_set <- validation

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")


#
# Y = mu + b_i + b_u where:
#   mu = the monthly average of all movie ratings by all users
#   b_i = the movie bias, b_i = mu - average rating of this movie by all users
#   b_u = the user bias, b_u = Y - mu - b_i



# Calculate monthly average ratings for all movies
t <- train_set %>% 
  mutate(month = round_date(as_datetime(timestamp), unit = "month")) %>% 
  group_by(month) %>% 
  summarise(monthly_mu = mean(rating))

# Add to dataset so we can use monthly average in user and item bias
train_set <- train_set %>% 
   mutate(month = round_date(as_datetime(timestamp), unit = "month")) %>% 
   left_join(t, by="month")

# calculate movie bias
movie_bias <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - monthly_mu) )

# calculate user bias
user_bias <- train_set %>%
  left_join(movie_bias, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - monthly_mu - b_i))

calc_rating <- function(mu, b_i, b_u, month) {
  
  # basic prediction
  pred <- mu + b_i + b_u
  
  # if rated before 2003 then round to whole star
  pred <- ifelse(month < ymd("2003-01-01"), 
                 round(pred),
                 pred)

  # Consider fewer 1/2 star ratings than whole star ratings
  # if pred is "near" to whole star then round to whole star
  # otherwise round to 1/2 star
  #pred <- 2.35
  pred <- ifelse(pred - as.integer(pred) < .1, 
                 floor(pred), 
          ifelse(pred - as.integer(pred) > .3,
                 ceiling(pred),
          as.integer(pred) + .5 ) )
  

  # recover extreme predictions
  pred <- if_else(pred < .5, .5, pred)
  pred <- if_else(pred > 5, 5, pred)
  
  return(pred)

  }


# calculate the predictions 
predictions <- test_set %>% 
  mutate(month = round_date(as_datetime(timestamp), unit = "month")) %>% 
  left_join(t, by="month") %>% 
  left_join(movie_bias, by="movieId") %>%
  left_join(user_bias, by="userId") %>%
  mutate(pred = calc_rating(monthly_mu, b_i, b_u, month)) %>%
 .$pred

# Create confusion matrix
predictions <- data.frame(predictions) %>% 
    mutate(rating = factor(predictions, levels = rating_levels))

test_set <- test_set %>% 
  mutate(rating = factor(rating, levels = rating_levels))

confusionMatrix(predictions$rating, test_set$rating)

```



