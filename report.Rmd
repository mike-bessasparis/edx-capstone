---
title: "Report"
output: html_notebook
---

```{r echo=FALSE, results='hide'}

library(tidyverse)
library(ggthemes)
library(lubridate)
library(caret)


#edx <- readRDS(file = "./rda/full_edx.rds")
#validation <- readRDS (file = "./rda/full_Validation.rds")

edx <- readRDS(file = "./rda/small_edx.rds")
validation <- readRDS (file = "./rda/small_Validation.rds")

#edx <- readRDS(file = "./rda/mini_edx.rds")
#validation <- readRDS (file = "./rda/mini_Validation.rds")

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")

all_model_predictions <-
  validation %>% 
  mutate(userId = as.character(userId),
         movieId = as.character(movieId)) %>% 
  select(userId, movieId, rating)


```

***
# Explore variables
```{r}

summary(edx)

head(edx)

```

## Response Variable: Rating
```{r}

summary(edx$rating)

```

```{r}

edx %>% ggplot(aes(x=rating)) +
  geom_histogram(binwidth = .5, col="grey") +
  scale_x_continuous(breaks = seq(0, 5, .5)) +
  labs(title = "Notice fewer 1/2 Stars")
  theme_economist_white()



```
## Other interesting variables
```{r}

#Find number of unique movies rated, number of unique users, and number of movies in each genre.

mjb1 <- length(unique(edx$movieId))
mjb2 <- length(unique(edx$userId))

rated_movies_grouped_by_genre <- edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) 

mjb4 <- nrow(rated_movies_grouped_by_genre)

```
In the dataset there are: 

<!-- - `r mjb2` unique users -->
<!-- - `r mjb1` unique movies rated -->
<!-- - `r mjb4` unique movie genres -->

Number of reviewed movies in each genre.  Note that a movie may be tagged with several genres, e.g., the movie "Boomerang" is classified as both a "Comedy" and a "Romance."
```{r}

edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(count = n()) %>% 
  ggplot() +
    geom_col(aes(x = reorder(genres, -count), y = count)) +
    coord_flip() +
    xlab("Genre") +
    ylab("Number of Movies") +
    theme_economist_white() +
    theme(axis.text.y.left = element_text(hjust = 1),
          panel.grid.major = element_blank(),
          axis.ticks.y.left = element_line(),
          axis.ticks.x.bottom = element_blank())

```

```{r}

edx %>% filter(genres == "(no genres listed)")

```


What are the top 10 most reviewed movies?
```{r}

edx %>% 
  group_by(title) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  top_n(10)

```
Who are the top 10 active reviewers?
```{r}

edx %>% 
  group_by(userId) %>% 
  summarise(count = n()) %>% 
  arrange(-count) %>% 
  top_n(10)

```
***
# Relationships (part 1)
## Numeric Correlations with Rating
No continuous numeric predictors to correlate with Rating; userId and movieId are discrete while timestamp is a date.

*** 
# Missing data, label encoding, and factorizing variables
```{r}
#
# make a copy of the data to modify so I don't have to rebuild if something goes bad.
#
edx_working <- edx

#
# First of all, I would like to see which variables contain missing values.
#
NAcol <- which(colSums(is.na(edx)) > 0)

```

There are `r length(which(colSums(is.na(edx)) > 0))` columns with at least one NA.

```{r}

# Label encoding
# There are no labels that are ordinal and should be encoded as a number.

#
# Separate and factorize the genres
#
edx_working <- edx_working %>% 
  separate_rows(genres, sep = "\\|") %>% 
  mutate(genre = factor(genres))

#
# Create a month-year from the timestamp
#
edx_working <- edx_working %>% 
  mutate(month = round_date(as_datetime(timestamp), unit = "month"),
         bimonth = round_date(as_datetime(timestamp), unit = "bimonth"),
         qtr = round_date(as_datetime(timestamp), unit = "quarter"),
         season = round_date(as_datetime(timestamp), unit = "season"),
         year = round_date(as_datetime(timestamp), unit = "year"))

#
# Factorizing the rating
#
# edx2 <- edx2 %>% 
#   mutate(rating = factor(rating))

edx_working %>% filter(genres == "(no genres listed)")
# "Pull My Daisy (1958)" by Kerouac
# IMDB lists the genre as "Short"


```

***
# Relationships (part 2)
Movie Genre and rating - is there a genre bias?
```{r}

library(tidyverse)

edx <- readRDS(file = "./rda/full_edx.rds")
edx_working <- edx

# combined genre and rating
edx_working %>% 
  group_by(genres) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  ggplot() +
    geom_point(aes(x = reorder(genres, avg_rating), y = avg_rating)) +
    coord_flip()

# individual genre and rating
edx_working %>% 
  separate_rows(genres, sep = "\\|") %>% 
  group_by(genres) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  ggplot() +
    geom_point(aes(x = reorder(genres, avg_rating), y = avg_rating)) +
    coord_flip() +
    ylim(c(0, 5))

```
Yes, there is a small genre-bias overall.

ANOVA
```{r}
library(tidyverse)

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")

edx <- readRDS(file = "./rda/small_edx.rds")
edx_working <- edx %>% 
  mutate(rating = factor(rating, rating_levels))

summary(aov(rating ~ userId + movieId, data = edx_working))

```



How are users, genres, and ratings related?  Do different users have a different genre-bias?

```{r}

library(tidyverse)

edx <- readRDS(file = "./rda/small_edx.rds")
edx_working <- edx

# combined genre and rating
edx_working %>% 
  group_by(genres) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  ggplot() +
    geom_point(aes(x = reorder(genres, avg_rating), y = avg_rating)) +
    coord_flip()

```

``` {r}


#
# Separate and factorize the genres
#
edx_working <- edx_working %>% 
  separate_rows(genres, sep = "\\|") %>% 
  mutate(genre = factor(genres))

edx_working %>% 
  ggplot() +
    geom_density(aes(x = rating, col = genre))



# edx_working %>% 
#   ggplot() +
#     geom_point(aes(y der(genres, -avg_rating), x = avg_rating)) +
#     xlim(0, 5)

# do users have extreme views of each genre
user_genre_affinity <- edx2 %>% 
  group_by(userId, genres) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  filter(avg_rating < 1 | avg_rating > 4.75)

user_genre_affinity %>% ggplot() +
    geom_raster(aes(y = genres, x = userId, fill = avg_rating)) +
    scale_fill_distiller(palette = "Spectral")


```

Average rating of each user.  Red represents a user who rated all movies the same (sd == 0).
```{r}
# user and rating
mjb1 <- edx %>% 
  group_by(userId) %>% 
  summarise(avg_rating = mean(rating), std_dev = sd(rating))%>% 
  arrange(-avg_rating)

outliers <- mjb1 %>% 
  filter(std_dev == 0)

ggplot() +
  geom_point(data = mjb1, aes(x = userId, y = avg_rating), color = "grey") +
  geom_point(data = outliers, aes(x = userId, y = avg_rating), color = "red")  

```
Let's look at the ratings of only these users
```{r}

edx %>%
  filter(userId %in% outliers$userId) %>% 
  ggplot() +
    geom_point(aes(x = as.factor(reorder(userId, rating)), y = rating))

```

How do ratings change over time?
```{r}

#
# make a copy of the data to modify so I don't have to rebuild if something goes bad.
#
edx2 <- edx %>% 
  mutate(timestamp = as_datetime(timestamp))

edx2 %>% 
  filter(timestamp > ymd("2002-01-01") & 
         timestamp < ymd("2004-01-01")) %>% 
  ggplot(aes(x = timestamp, y = rating)) +
    geom_point() +
    labs(title = "1/2 star ratings start on 2003-05-15")

edx2 %>% 
  mutate(time_bin = round_date(timestamp, unit = "month")) %>% 
  group_by(time_bin) %>% 
  summarise(avg_rating = mean(rating)) %>% 
  ggplot(aes(x = time_bin, y = avg_rating)) +
    geom_point() +
    geom_smooth(se = FALSE) +
    labs(title = "Monthly average movie rating changes over time.") +
    theme_economist_white()  

```


# Models

## NaiveBayes model
Using formula rating ~ userId + MovieId + month.  
Tried adding genre but didn't add to accuracy but took much longer to build model.
```{r}

library(tidyverse)
library(caret)
library(lubridate)

edx <- readRDS(file = "./rda/small_edx.rds")
validation <- readRDS (file = "./rda/small_Validation.rds")

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")

train_set <- edx %>% 
  mutate(month = as.character(round_date(as_datetime(timestamp), unit = "month")),
         rating = factor(rating, levels = rating_levels))

test_set <- validation %>% 
  mutate(month = as.character(round_date(as_datetime(timestamp), unit = "month")),
         rating = factor(rating, levels = rating_levels))

fit <- train(rating ~ userId + movieId + month, 
             method = "naive_bayes", 
             data = train_set)

naive_bayes_predictions <- predict(fit, test_set, type = "raw")

final_nb_predictions <- 
  data.frame(userId = as.character(validation$userId),
             movieId = as.character(validation$movieId),
             nb_preds = naive_bayes_predictions,
             stringsAsFactors = FALSE)

confusionMatrix(final_nb_predictions$nb_preds, test_set$rating)

#
# add predicitions to ensemble
#
final_nb_predictions <- final_nb_predictions %>% 
  mutate(nb_preds = as.double(nb_preds))

all_model_predictions <- all_model_predictions %>% 
    left_join(final_nb_predictions, by = c("userId", "movieId"))


rm(train_set, test_set, fit, naive_bayes_predictions, final_nb_predictions)

```

## IBCF
```{r}
library(caret)
library(tidyverse)
library(recommenderlab)

edx <- readRDS(file = "./rda/small_edx.rds")
validation <- readRDS (file = "./rda/small_Validation.rds")

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")

# can't afford to run on entire dataset.  just use the top_n rated movies.
# temp <- edx %>% 
#   group_by(movieId) %>% 
#   summarise(count = n()) %>% 
# #  top_n(1000, wt = count) %>% 
#   arrange(-count) %>% 
#   mutate(running_total = cumsum(count))

#
# reduce the size of the training set to only those items in the validation set
# no reason to use resources to predict ratings on non-requested items
#
train_set <- edx %>%
  filter(movieId %in% unique(validation$movieId))

test_set <- validation

r <- as(train_set, "realRatingMatrix")
rec.model <- Recommender(data = r,
                        method = "IBCF",
                        parameter = list(method = "Cosine"))

pred <- predict(rec.model, r, type = "ratings")
pred_matrix <- as(pred, "matrix")

# make into a df
ibcf_preds <- pred_matrix %>% 
  as.data.frame.matrix() %>% 
  rownames_to_column(var = "userId") %>% 
  gather(key = movieId, value = IBCF_rating, -userId)

test_set <- test_set %>% 
 mutate(userId = as.character(userId),
        movieId = as.character(movieId)) %>% 
 select(userId, movieId)

final_ibcf_predictions <- left_join(test_set, ibcf_preds)

#
# add predictions to ensemble
#
all_model_predictions <- all_model_predictions %>% 
    left_join(final_ibcf_predictions, by = c("userId", "movieId"))

rm(train_set, test_set, rec.model, pred, pred_matrix, r, ibcf_preds, final_ibcf_predictions)

```

## RecommenderLab - UBCF
```{r}

# library(recommenderlab)
# library(tidyverse)
# library(caret)
# 
# round_rating <- function(pred) {
#   
#   pred <- round(pred/0.5)*0.5
#   
#   return(pred)
# 
# }
# 
# train_set <- edx
# test_set <- validation
# 
# train.matrix <- as(train_set, "realRatingMatrix")
# 
# target_users <- as.character(unique(test_set$userId))
# 
# # Model creation
# Rec.model <- Recommender(train.matrix, method = "UBCF")
# 
# q <- predict(Rec.model, train.matrix[target_users], type = "ratings")
# 
# # convert from matrix to df to make joins easier
# ubcf_preds <- as(q, "matrix") %>% 
#   as.data.frame() %>% 
#   rownames_to_column(var = "userId") %>% 
#   gather(key = movieId, value = rating, -userId)
# 
# # Create confusion matrix
# rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")
# ubcf_preds <- ubcf_preds %>% 
#     mutate(pred_rating = factor(round_rating(rating), levels = rating_levels)) %>% 
#     select(-rating)
# 
# test_set <- test_set %>% 
#   mutate(rating = factor(rating, levels = rating_levels),
#          userId = as.character(userId),
#          movieId = as.character(movieId))
# 
# test_set2 <- test_set %>% 
#   left_join(ubcf_preds)
# 
# confusionMatrix(test_set2$rating, test_set2$pred_rating)

```

## Custom model
```{r}

library(caret)
library(tidyverse)
library(lubridate)

edx <- readRDS(file = "./rda/small_edx.rds")
validation <- readRDS (file = "./rda/small_Validation.rds")

train_set <- edx %>% 
  mutate(userId = as.character(userId),
         movieId = as.character(movieId),
         month = round_date(as_datetime(timestamp), unit = "month"))

test_set <- validation %>%  
  mutate(userId = as.character(userId),
         movieId = as.character(movieId),
         month = round_date(as_datetime(timestamp), unit = "month"))

#
# Y = mu + b_i + b_u where:
#   mu = the monthly average of all movie ratings by all users
#   b_i = the movie bias, b_i = mu - average rating of this movie by all users
#   b_u = the user bias, b_u = Y - mu - b_i
#

# Calculate monthly average ratings for all movies
t <- train_set %>% 
  group_by(month) %>% 
  summarise(monthly_mu = mean(rating))

# Add to dataset so we can use monthly average in user and item bias
train_set <- train_set %>% 
   left_join(t, by="month")

# calculate movie bias
# lambda manually tuned
lambda1 <- 10
movie_bias <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - monthly_mu) / (n() + lambda1) )

# calculate user bias
# lambda manually tuned
lambda2 <- 5
user_bias <- train_set %>%
  left_join(movie_bias) %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - monthly_mu) / (n() + lambda2) )


calc_rating <- function(mu, b_i, b_u, month) {
  
  # basic prediction
  pred <- mu + b_i + b_u
  
  # if rated before 2003 then round-upwards to whole star
  # this produces better accuracy than either round or floor
  pred <- ifelse(month < ymd("2003-05-15"), 
                 ceiling(pred),
                 pred)

  #
  # Consider fewer 1/2 star ratings than whole star ratings
  # if pred is "near" to whole star then round to whole star
  # otherwise round to 1/2 star
  #
  # rounding thresholds (.4 and .6) optimized by multiple trails
  #
  pred <- ifelse(pred - as.integer(pred) < .4, 
                 floor(pred), 
          ifelse(pred - as.integer(pred) > .6,
                 ceiling(pred),
          as.integer(pred) + .5 ) )
  

  # recover extreme predictions
  pred <- if_else(pred < .5, .5, pred)
  pred <- if_else(pred > 5, 5, pred)
  
  return(pred)

}

# calculate the predictions 
final_custom_predictions <- test_set %>% 
  left_join(t, by="month") %>% 
  left_join(movie_bias, by="movieId") %>%
  left_join(user_bias, by="userId") %>%
  mutate(custom_pred = calc_rating(monthly_mu, b_i, b_u, month)) %>% 
  select(userId, movieId, custom_pred)

#
# add predicitions to ensemble
#
all_model_predictions <- all_model_predictions %>% 
    left_join(final_custom_predictions, by = c("userId", "movieId"))

# Create confusion matrix

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")

final_custom_predictions <- final_custom_predictions %>% 
  mutate(custom_pred = factor(custom_pred, levels = rating_levels))

test_set <- test_set %>% 
  mutate(rating = factor(rating, levels = rating_levels))

rm(final_custom_predictions, movie_bias, t, test_set, train_set, user_bias)

```


## Ensemble Evaluation
```{r}
library(tidyverse)
library(caret)

mjb <- all_model_predictions %>% 
  select(-userId, -movieId, -rating) %>% 
  as.matrix()

rating_levels <- c("0.5", "1", "1.5", "2", "2.5", "3", "3.5", "4", "4.5", "5")
all_model_predictions$ensemble_pred <- round(rowMeans(mjb, na.rm = TRUE) / 0.5) * 0.5

confusionMatrix(factor(all_model_predictions$ensemble_pred, rating_levels), 
                factor(validation$rating, rating_levels))

```

