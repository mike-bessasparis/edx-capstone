---
title: "R Notebook"
output: html_notebook
--- 

``` {r}

library(tidyverse)
library(caret)
library(lubridate)
library(doParallel)

# setup for parallel processing 
cl <- makePSOCKcluster(8)
registerDoParallel(cl)


edx <- readRDS(file = "./rda/edx.rds")
validation <- readRDS (file = "./rda/validation.rds")

# important to not use validation data during model development
# to keep the code uncluttered I use this to decide what should be
# used as the test_set rather than changing datasets for each model.
# set the type of model run here by removing a comment
#
#type_of_run <- "validation"
type_of_run <- "develop"

```

Use the edx data as the base to create a train_set and test_set.
``` {r}

# test_set set will be 10% of edx data
set.seed(1)
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
train_set <- edx[-test_index,]
temp <- edx[test_index,]

# Make sure userId and movieId in test_set are also in train_set
test_set <- temp %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)


RMSE <- function(true_ratings, predicted_ratings) {
  sqrt(mean((true_ratings - predicted_ratings)^2))
}


# use the test_set to evaluate model when we're building the model
# use the validation data to evaluate the completed model
test_set <- if_else(type_of_run == "develop", test_set, validation)


rm(edx, removed, test_index, temp)
```

## Feature Engineering (from EDA)
Add interesting features discovered from EDA.  As a convenience I add features to both the train_set and test_set here in one place.  The lambda parameters used in the movie and user bias calculations have been tuned by a 5-fold cross-validation done using only the train_set outside of this report.  The cross-validation code is included (but not run) at the end of this report.  
``` {r}

# create a reviewed_date and reviewed_year feature
train_set <- train_set %>%
  mutate(review_date = date(as_datetime(timestamp)),
         review_year = year(review_date))
test_set <- test_set %>%
  mutate(review_date = date(as_datetime(timestamp)),
         review_year = year(review_date))



mu <- mean(train_set$rating)



# find b_i(t), the rating bias for each movie as a function of time (year)
lambda1 <- 3
movie_time_bias <- train_set %>% 
  group_by(movieId, review_year) %>% 
  summarize(b_i_time = sum(rating - mu) / (n() + lambda1))
train_set <- left_join(train_set, movie_time_bias, by = c("movieId", "review_year"))



# find the user rating bias for each user
lambda2 <- 5
user_bias <- train_set %>% 
  group_by(userId) %>% 
  summarize(b_u = sum(rating - mu - b_i_time) / (n() + lambda2) )
train_set <- left_join(train_set, user_bias, by = "userId")



# create released_year and movie_age_at_rating features
train_set <- train_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year)
test_set <- test_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year)



# Create the number of times a movie has been reviewed predictor
q <- train_set %>% 
  group_by(movieId) %>% 
  summarise(num_of_reviews_of_movie = n())

train_set <- train_set %>%
  left_join(q, by = "movieId")
test_set <- test_set %>% 
  left_join(q, by = "movieId")



# create dataframe to record individual model predictions
ensemble_preds <- test_set %>% 
  select(userId, movieId)



rm(lambda1, lambda2, q)

```

## Custom Model (Netflix)
This is the model we started in class.  I copied the method from the class and extended that model using the reference provided in the class: "The BellKor Solution to the Netflix Grand Prize", Yehuda Koren, August 2009.  I implemented only a simplified version of the movie bias as a function of time referenced in the paper.  I correct for estimates outside the given rating range of 0.5 - 5.

``` {r}

# r = mu + b_i(t) + b_u


# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
pred_custom <- test_set %>%
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>%
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%
  left_join(user_bias, by = "userId") %>%
  mutate(pred_c = mu + b_i_time + b_u)


# recover predictions outside of rating range
pred_custom <- pred_custom %>% 
  select(userId, movieId, pred_c) %>% 
  mutate(pred_c = if_else(pred_c > 5, 5, pred_c),
         pred_c = if_else(pred_c < 0.5, 0.5, pred_c))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_custom, by = c("userId", "movieId"))

rmse_custom <- RMSE(pred_custom$pred_c, test_set$rating)

rm(pred_custom)

```

## XGBoost
Selection of features was made over many previous interations of train() using a small sample of the train_set.  The final set of features showed the best promise of working well on the entire data set.  The model has been previously trained to optimize parameters.  Code is included at the end of this notebook for completeness.  I use train() here for convenience.
``` {r}

cl <- makePSOCKcluster(8)
registerDoParallel(cl)

start_xgb <- Sys.time()

xgbGrid <- expand.grid(gamma = 0,
                       min_child_weight = 1,
                       nrounds = 200,
                       max_depth = 3,
                       eta = 0.3,
                       colsample_bytree = 0.8,
                       subsample = 1)

fit <- train(rating ~ b_u + b_i_time + movie_age_at_rating + num_of_reviews_of_movie,
             data = train_set,
             method = "xgbTree",
             tuneGrid = xgbGrid,
             trControl = trainControl(method = "none"),
             preProcess = c("center", "scale"))


# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
test_set_working <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_bias, by = "userId")

q <- predict(fit, test_set_working)

pred_xgb <- data.frame(userId = test_set_working$userId, movieId = test_set_working$movieId, pred_x = q)

# recover predictions outside of rating range
pred_xgb <- pred_xgb %>% 
  mutate(pred_x = if_else(pred_x > 5, 5, pred_x),
         pred_x = if_else(pred_x < 0.5, 0.5, pred_x))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_xgb, by = c("userId", "movieId"))

rmse_xgb <- RMSE(pred_xgb$pred_x, test_set$rating)

rm(test_set_working, xgbGrid, q, pred_xgb, start_xgb)

```


## Neural Network
Model has been previously trained and parameters optimized by caret::train().  Code is included at the end of this notebook for completeness.
```{r}

# setup for parallel processing 
cl <- makePSOCKcluster(8)
registerDoParallel(cl)
start_nnet <- Sys.time()

nnetGrid <- expand.grid(size = 3,
                       decay = 1e-4)

# train model using previously identified parameters
fit <- train(rating ~ b_u + b_i_time + movie_age_at_rating + num_of_reviews_of_movie,
             data = train_set,
             method = "nnet",
             tuneGrid = nnetGrid,
             trControl = trainControl(method = "none"),
             preProcess = c("center", "scale"),
             linout = TRUE)

# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
test_set_working <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_bias, by = "userId")

q <- predict(fit, test_set_working)

pred_nnet <- data.frame(userId = test_set_working$userId, movieId = test_set_working$movieId, pred_n = q)

# recover predictions outside of rating range
pred_nnet <- pred_nnet %>% 
  mutate(pred_n = if_else(pred_n > 5, 5, pred_n),
         pred_n = if_else(pred_n < 0.5, 0.5, pred_n))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_nnet, by = c("userId", "movieId"))

rmse_nnet <- RMSE(pred_nnet$pred_n, test_set$rating)

rm(nnetGrid, fit, q, pred_nnet, test_set_working, start_nnet)

```

## Use ensemble to create final predictions
```{r}

ensemble_preds <- ensemble_preds %>% 
  mutate (final_pred = (pred_c + pred_x + pred_n) / 3)

#
# for final model development only
#
RMSE_ensemble <- RMSE(test_set$rating, ensemble_preds$final_pred)


#
# for final validation only
#
#RMSE_ensemble <- RMSE(validation$rating, ensemble_preds$final_pred)

rm(movie_time_bias, user_bias, mu, train_set, test_set, edx, validation, RMSE, cl)

```


```{r eval = FALSE}

# # # # # # 
#
# manual cross-validation code used to tune parameters for user and movie bias.
#
# # # # # # 
#
# cv_splits <- createFolds(train_set$rating, k = 5, returnTrain = FALSE)
# 
# mjb <- data.frame(matrix(nrow = 0, ncol = 3))
# 
# for (lambda1 in 1:24) {
#   print(paste("lambda1", lambda1))
#   for (lambda2 in 1:9) {
#         r <- numeric()
#         print(paste("..lambda2", lambda2))
#         for (i in 1:length(cv_splits)) {
#           print(paste("....fold", i))
#           test_i <- unlist(cv_splits[i])
#           cv_test_set <- train_set[test_i,]
#           cv_train_set <- train_set[-test_i,]
#           
#             # find b_i(t), the rating bias for each movie as a function of time (year)
#           #lambda1 <- 0 #3
#           movie_time_bias <- cv_train_set %>% 
#             group_by(movieId, review_year) %>% 
#             summarize(b_i_time = sum(rating - mu) / (n() + lambda1))
#           cv_train_set <- left_join(cv_train_set, movie_time_bias, by = c("movieId", "review_year"))
#           
#           # find the user rating bias for each user
#           #lambda2 <- 0 #5
#           user_bias <- cv_train_set %>% 
#             group_by(userId) %>% 
#             summarize(b_u = sum(rating - mu - b_i_time) / (n() + lambda2) )
#           cv_train_set <- left_join(cv_train_set, user_bias, by = "userId")
#           
#           cv_pred <- cv_test_set %>% 
#             left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
#             mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
#             left_join(user_bias, by = "userId") %>% 
#             mutate(pred_c = mu + b_i_time + b_u)
#         
#             r <- rbind(r, RMSE(cv_pred$pred_c, cv_test_set$rating))
#         
#         }
#       
#     rmse <- mean(r)
#     mjb <- rbind(mjb, data.frame(lambda1, lambda2, rmse))
#       
#     }
# }
# 
# mjb <- arrange(mjb, rmse)
# print(mjb)



# # # # # #
#
# code used to tune parameters for XGBoost model
#
# # # # # #
#
# set.seed(1)
# fitControl <- trainControl(method = "cv", number = 5)
#
# # choose sample of train_set to tune parameters, 
# # don't have enough computing resources to use the entire train_set
# probe_set <- sample_n(train_set, 1000000)
# 
# fit <- train(rating ~ b_u + b_i_time + movie_age_at_rating + num_of_reviews_of_movie + movie_release_year,
#              data = probe_set,
#              method = "xgbTree",
#              tuneGrid = xgbGrid,
#              trControl = fitControl,
#              preProcess = c("center", "scale"))
# 



# # # # # #
#
# code used to tune parameters for NNet model
#
# # # # # #
#
# set.seed(1)
# probe_set <- sample_n(train_set, 1000000)
# 
# fitControl <- trainControl(method = "cv", number = 5)
# 
# fit <- train(rating ~ b_u + b_i_time + movie_age_at_rating + num_of_reviews_of_movie + movie_release_year,
#              data = probe_set,
#              method = "nnet",
#              trControl = fitControl,
#              preProcess = c("center", "scale"),
#              linout = TRUE)


```

