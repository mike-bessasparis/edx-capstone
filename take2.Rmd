---
title: "R Notebook"
output: html_notebook
---

``` {r}
library(tidyverse)
library(caret)


edx <- readRDS(file = "./rda/full_edx.rds")
validation <- readRDS (file = "./rda/full_Validation.rds")

#edx <- readRDS(file = "./rda/small_edx.rds")
#validation <- readRDS (file = "./rda/small_Validation.rds")

#edx <- readRDS(file = "./rda/mini_edx.rds")
#validation <- readRDS (file = "./rda/mini_Validation.rds")


```


``` {r}

train_set <- edx
test_set <- validation

RMSE <- function(true_ratings, predicted_ratings) {
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

#rm(edx, validation)

```

## Feature Engineering (from EDA)
``` {r}
library(lubridate)

# factorize userId and movieId
# create a reviewed_date feature
train_set <- train_set %>%
  mutate(userId = factor(userId),
         movieId = factor(movieId),
         review_date = date(as_datetime(timestamp))) %>% 
  select(-timestamp)
test_set <- test_set %>%
  mutate(userId = factor(userId),
         movieId = factor(movieId),
         review_date = date(as_datetime(timestamp))) %>% 
  select(-timestamp)


# create a reviewed_year feature
train_set <- train_set %>%
  mutate(reviewed_year = as.integer(year(review_date)))
test_set <- test_set %>%
  mutate(reviewed_year = as.integer(year(review_date)))


# create released_year and movie_age_at_rating features
train_set <- train_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year) %>% 
  select(-title)
test_set <- test_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year) %>% 
  select(-title)

train_set <- train_set %>% 
  select(-genres)
test_set <- test_set %>% 
  select(-genres)


```



## Custom Model (Netflix)
``` {r}

# r = mu + b_i(t) + b_u

# find the overall average rating
mu <- mean(train_set$rating)

# find b_i(t), the rating bias for each movie as a function of time (year)
lambda1 <- 3
movie_time_bias <- train_set %>% 
  group_by(movieId, reviewed_year) %>% 
  summarize(b_i_time = sum(rating - mu) / (n() + lambda1))

# find the rating bias for each user
# (the "leftover" after finding b_i)
lambda2 <- 5
user_avgs <- train_set %>% 
  left_join(movie_time_bias, by = c("movieId", "reviewed_year")) %>% 
  group_by(userId) %>% 
  summarize(b_u = sum(rating - mu - b_i_time) / (n() + lambda2) )

# combine and make predictions
predicted_ratings <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "reviewed_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_avgs, by = "userId") %>% 
  mutate(pred = mu + b_i_time + b_u)

predicted_ratings <- predicted_ratings %>% 
  select(userId, movieId, pred)

q <- RMSE(test_set$rating, predicted_ratings$pred)

rm(movie_time_bias, predicted_ratings, user_avgs, lambda1, lambda2, mu)

```

## XGBoost
``` {r eval=FALSE}

mjb_train_set <- train_set %>% 
  mutate(movieId = as.integer(movieId),
         userId = as.integer(userId))

mjb_test_set <- test_set %>% 
  mutate(movieId = as.integer(movieId),
         userId = as.integer(userId))

fitControl <- trainControl(method = "cv", number = 2)

xgbGrid <- expand.grid(gamma = 0,
                       min_child_weight = 1,
                       nrounds = 300,
                       max_depth = 7,
                       eta = 0.3,
                       colsample_bytree = 0.8,
                       subsample = 1)

start <- Sys.time()

fit <- train(rating ~ userId + movieId + reviewed_year + movie_release_year + movie_age_at_rating,
             data = mjb_train_set,
             method = "xgbTree",
             tuneGrid = xgbGrid,
             trControl = fitControl, 
             preProcess = c("center", "scale"))

end <-Sys.time()
mjb <- end - start

q <- predict(fit, mjb_test_set)

final_xgb_predictions <- data.frame(userId = as.character(mjb_test_set$userId), movieId = as.character(mjb_test_set$movieId), xgb_pred = q)

RMSE_xgb <- RMSE(mjb_test_set$rating, q)


```

## IBCF  
Tried this with one predictor on full dataset and it took over 12 hours to complete with RMSE > 1.  Need more than one predictor but
don't have resources.
``` {r eval=FALSE}

# library(recommenderlab)
# 
# # can't afford to run on entire dataset.  just use the top_n number of rated movies.
# temp <- edx %>%
#   group_by(movieId) %>%
#   summarise(count = n()) %>%
#   top_n(1000, wt = count) %>%
#   arrange(-count) %>%
#   mutate(running_total = cumsum(count))
# 
# train_set <- semi_join(edx, temp, by = "movieId")
# 
# 
# #
# # reduce the size of the training set to only those items in the validation set
# # no reason to use resources to predict ratings on non-requested items
# #
# # train_set <- train_set %>%
# #   filter(movieId %in% unique(validation$movieId))
# 
# 
# r <- as(train_set, "realRatingMatrix")
# rec.model <- Recommender(data = r,
#                         method = "IBCF",
#                         parameter = list(method = "Cosine"))
# 
# pred <- predict(rec.model, r, type = "ratings")
# pred_matrix <- as(pred, "matrix")
# 
# # make into a df to visualize and join easier than a matrix
# ibcf_preds <- pred_matrix %>% 
#   as.data.frame.matrix() %>% 
#   rownames_to_column(var = "userId") %>% 
#   gather(key = movieId, value = IBCF_rating, -userId)
# 
# test_set <- test_set %>% 
#  mutate(userId = as.character(userId),
#         movieId = as.character(movieId)) %>% 
#  select(userId, movieId)
# 
# mu <- mean(train_set$rating)
# 
# # Join the predictions to the test_set
# final_ibcf_predictions <- left_join(test_set, ibcf_preds)
# 
# final_ibcf_predictions <- final_ibcf_predictions %>% 
#   mutate(IBCF_rating = if_else(is.na(IBCF_rating), mu, IBCF_rating))
# 
# 
# RMSE_IBCF <- RMSE(validation$rating, final_ibcf_predictions$IBCF_rating)

```