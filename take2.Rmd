---
title: "R Notebook"
output: html_notebook
---

Overall approach is to create an ensemble of predictions from three different models (custom NetFlix, XGBoost, and NeuralNet) and average the ratings together for each movie to create a final prediciton.

``` {r}
library(tidyverse)
library(caret)
library(lubridate)


edx <- readRDS(file = "./rda/full_edx.rds")
validation <- readRDS (file = "./rda/full_Validation.rds")

#edx <- readRDS(file = "./rda/small_edx.rds")
#validation <- readRDS (file = "./rda/small_Validation.rds")

```

I use the edx data as my train_set and the validation data, after removing the actual rating, as the test_set.
``` {r}

train_set <- edx
test_set <- validation %>% select(-rating)

RMSE <- function(true_ratings, predicted_ratings) {
  sqrt(mean((true_ratings - predicted_ratings)^2))
}


```

## Feature Engineering (from EDA)
Add interesting features discovered from EDA.  As a convenience I add features to both the train_set and test_set here in one place.  The lambda parameters used in the movie and user bias calculations have been tuned by a 5-fold cross-validation done using only the train_set outside of this report.  The cross-validation code is included (but not run) at the end of this report.  
``` {r}

# create a reviewed_date and reviewed_year feature
train_set <- train_set %>%
  mutate(review_date = date(as_datetime(timestamp)),
         review_year = year(review_date))
test_set <- test_set %>%
  mutate(review_date = date(as_datetime(timestamp)),
         review_year = year(review_date))



mu <- mean(train_set$rating)



# find b_i(t), the rating bias for each movie as a function of time (year)
lambda1 <- 3
movie_time_bias <- train_set %>% 
  group_by(movieId, review_year) %>% 
  summarize(b_i_time = sum(rating - mu) / (n() + lambda1))
train_set <- left_join(train_set, movie_time_bias, by = c("movieId", "review_year"))

# find the user rating bias for each user
lambda2 <- 5
user_bias <- train_set %>% 
  group_by(userId) %>% 
  summarize(b_u = sum(rating - mu - b_i_time) / (n() + lambda2) )
train_set <- left_join(train_set, user_bias, by = "userId")



# create released_year and movie_age_at_rating features
train_set <- train_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year)
test_set <- test_set %>%
  mutate(movie_release_year = as.integer(str_extract(str_extract(title, "\\(\\d{4}\\)"), "\\d{4}")),
         movie_age_at_rating = year(review_date) - movie_release_year)



# Create the number of times a movie has been reviewed predictor
q <- train_set %>% 
  group_by(movieId) %>% 
  summarise(num_of_reviews_of_movie = n())

train_set <- train_set %>%
  left_join(q, by = "movieId")
test_set <- test_set %>% 
  left_join(q, by = "movieId")



# create dataframe to record individual model predictions
ensemble_preds <- test_set %>% 
  select(userId, movieId)



rm(lambda1, lambda2, q)

```

## Custom Model (Netflix)
This is the model we started in class.  I copied the method from the class and extended that model using the reference provided in the class: 
"The BellKor Solution to the Netflix Grand Prize", Yehuda Koren, August 2009.  I implemented only a simplified version of the movie bias as a function of time referenced in the paper.  I also corrected for estimates outside the given rating range of 0.5 - 5.
``` {r}

# r = mu + b_i(t) + b_u

# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
pred_custom <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_bias, by = "userId") %>% 
  mutate(pred_c = mu + b_i_time + b_u)

# recover predictions outside of rating range
pred_custom <- pred_custom %>% 
  select(userId, movieId, pred_c) %>% 
  mutate(pred_c = if_else(pred_c > 5, 5, pred_c),
         pred_c = if_else(pred_c < 0.5, 0.5, pred_c))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_custom, by = c("userId", "movieId"))

rm(pred_custom)

```

## XGBoost
``` {r}

fitControl <- trainControl(method = "cv", number = 3)

xgbGrid <- expand.grid(gamma = 0,
                       min_child_weight = 1,
                       nrounds = 300,
                       max_depth = 7,
                       eta = 0.3,
                       colsample_bytree = 0.8,
                       subsample = 1)

start_xgb <- Sys.time()

fit <- train(rating ~ b_u + b_i_time + movie_age_at_rating + num_of_reviews_of_movie,
             data = train_set,
             method = "xgbTree",
             tuneGrid = xgbGrid,
             trControl = fitControl,
             preProcess = c("center", "scale"))

# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
test_set_working <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_bias, by = "userId")

q <- predict(fit, test_set_working)

pred_xgb <- data.frame(userId = test_set_working$userId, movieId = test_set_working$movieId, pred_x = q)

# recover predictions outside of rating range
pred_xgb <- pred_xgb %>% 
  mutate(pred_x = if_else(pred_x > 5, 5, pred_x),
         pred_x = if_else(pred_x < 0.5, 0.5, pred_x))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_xgb, by = c("userId", "movieId"))

rm(fitControl, test_set_working, xgbGrid, q, pred_xgb, start_xgb)

```


## Neural Network
```{r}

fitControl <- trainControl(method = "cv", number = 2)
nnetGrid <- expand.grid(size = 3,
                       decay = 1e-4)

start_nnet <- Sys.time()

fit <- train(rating ~ b_u + b_i_time + num_of_reviews_of_movie,
             data = train_set,
             method = "nnet",
             trControl = fitControl, 
             tuneGrid = nnetGrid,
             preProcess = c("center", "scale"),
             linout = TRUE)


# add movie and user bias calculated from the train_set and make predictions
# mutate is to put 0 where we don't have a calculated movie_time_bias
test_set_working <- test_set %>% 
  left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
  mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
  left_join(user_bias, by = "userId")

q <- predict(fit, test_set_working)

pred_nnet <- data.frame(userId = test_set_working$userId, movieId = test_set_working$movieId, pred_n = q)

# recover predictions outside of rating range
pred_nnet <- pred_nnet %>% 
  mutate(pred_n = if_else(pred_n > 5, 5, pred_n),
         pred_n = if_else(pred_n < 0.5, 0.5, pred_n))

ensemble_preds <- ensemble_preds %>% 
  left_join(pred_nnet, by = c("userId", "movieId"))

rm(fitControl, nnetGrid, fit, q, pred_nnet, test_set_working, start_nnet)

```

## Use ensemble to create final predictions
```{r}

ensemble_preds <- ensemble_preds %>% 
  mutate (final_pred = (pred_c + pred_x + pred_n) / 3)

RMSE_ensemble <- RMSE(validation$rating, ensemble_preds$final_pred)

rm(movie_time_bias, user_bias, mu, train_set, test_set, edx, validation, RMSE)

```

### manual cross-validation code used to tune parameters for user and movie bias.
```{r eval = FALSE}

# cv_splits <- createFolds(train_set$rating, k = 5, returnTrain = FALSE)
# 
# mjb <- data.frame(matrix(nrow = 0, ncol = 3))
# 
# for (lambda1 in 1:24) {
#   print(paste("lambda1", lambda1))
#   for (lambda2 in 1:9) {
#         r <- numeric()
#         print(paste("..lambda2", lambda2))
#         for (i in 1:length(cv_splits)) {
#           print(paste("....fold", i))
#           test_i <- unlist(cv_splits[i])
#           cv_test_set <- train_set[test_i,]
#           cv_train_set <- train_set[-test_i,]
#           
#             # find b_i(t), the rating bias for each movie as a function of time (year)
#           #lambda1 <- 0 #3
#           movie_time_bias <- cv_train_set %>% 
#             group_by(movieId, review_year) %>% 
#             summarize(b_i_time = sum(rating - mu) / (n() + lambda1))
#           cv_train_set <- left_join(cv_train_set, movie_time_bias, by = c("movieId", "review_year"))
#           
#           # find the user rating bias for each user
#           #lambda2 <- 0 #5
#           user_bias <- cv_train_set %>% 
#             group_by(userId) %>% 
#             summarize(b_u = sum(rating - mu - b_i_time) / (n() + lambda2) )
#           cv_train_set <- left_join(cv_train_set, user_bias, by = "userId")
#           
#           cv_pred <- cv_test_set %>% 
#             left_join(movie_time_bias, by = c("movieId", "review_year")) %>% 
#             mutate(b_i_time = if_else(is.na(b_i_time), 0, b_i_time)) %>%   
#             left_join(user_bias, by = "userId") %>% 
#             mutate(pred_c = mu + b_i_time + b_u)
#         
#             r <- rbind(r, RMSE(cv_pred$pred_c, cv_test_set$rating))
#         
#         }
#       
#     rmse <- mean(r)
#     mjb <- rbind(mjb, data.frame(lambda1, lambda2, rmse))
#       
#     }
# }
# 
# mjb <- arrange(mjb, rmse)
# print(mjb)


```

