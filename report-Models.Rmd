---
title: "Report-Models"
output:
  pdf_document: default
  html_notebook: default
---

```{r echo=FALSE, results='hide'}

library(tidyverse)

# edx <- readRDS(file = "./rda/full_edx.rds")
# validation <- readRDS (file = "./rda/full_Validation.rds")

edx <- readRDS(file = "./rda/small_edx.rds")
validation <- readRDS (file = "./rda/small_Validation.rds")

#edx <- readRDS(file = "./rda/mini_edx.rds")
#validation <- readRDS (file = "./rda/mini_Validation.rds")

all_model_predictions <-
  validation %>% 
  mutate(userId = as.character(userId),
         movieId = as.character(movieId)) %>% 
  select(userId, movieId, rating)

RMSE <- function(true_ratings, predicted_ratings) {
    sqrt(mean((true_ratings - predicted_ratings)^2))
  }

```


# Models

## GBM
```{r}

library(caret)
library(tidyverse)
library(lubridate)

train_set <- edx #%>% 
  # mutate(userId = as.character(userId),
  #        movieId = as.character(movieId),
  #        rating_date = round_date(as_datetime(timestamp), unit = "day"))

test_set <- validation #%>%  
  # mutate(userId = as.character(userId),
  #        movieId = as.character(movieId),
  #        rating_date = round_date(as_datetime(timestamp), unit = "day"))

fitControl <- trainControl(method = "cv", number = 2)

gbmGrid <- expand.grid(n.trees = 4920,
                       interaction.depth = 1,
                       shrinkage = 0.01,
                       n.minobsinnode = 11)

start <- Sys.time()

fit <- train(rating ~ userId + movieId + timestamp,
             data = train_set,
             method = "gbm",
             tuneGrid = gbmGrid,
             trControl = fitControl)

end <-Sys.time()
mjb <- end - start

q <- predict(fit, test_set)

final_gbm_predictions <- data.frame(userId = as.character(test_set$userId), movieId = as.character(test_set$movieId), gbm_pred = q)

RMSE_gbm <- RMSE(test_set$rating, q)

#
# add predictions to ensemble
#
all_model_predictions <- all_model_predictions %>% 
    left_join(final_gbm_predictions, by = c("userId", "movieId"))

```


## Random Forest

```{r}

library(caret)
library(tidyverse)
library(lubridate)

train_set <- edx 
test_set <- validation 

fit <- train(rating ~ movieId + userId + timestamp,
             nTree = 10,
             method = "Rborist",
             data = train_set)

q <- predict(fit, test_set)

final_rf_predictions <- data.frame(userId = as.character(test_set$userId), movieId = as.character(test_set$movieId), rf_pred = q)

RMSE_RandomForest <- RMSE(test_set$rating, q)

#
# add predictions to ensemble
#
all_model_predictions <- all_model_predictions %>% 
    left_join(final_rf_predictions, by = c("userId", "movieId"))



```


## IBCF
```{r eval=FALSE}

library(caret)
library(tidyverse)
library(recommenderlab)

# can't afford to run on entire dataset.  just use the top_n number of rated movies.
temp <- edx %>%
  group_by(movieId) %>%
  summarise(count = n()) %>%
  top_n(100, wt = count) %>%
  arrange(-count) %>%
  mutate(running_total = cumsum(count))

train_set <- semi_join(edx, temp, by = "movieId")


#
# reduce the size of the training set to only those items in the validation set
# no reason to use resources to predict ratings on non-requested items
#
train_set <- train_set %>%
  filter(movieId %in% unique(validation$movieId))

test_set <- validation

r <- as(train_set, "realRatingMatrix")
rec.model <- Recommender(data = r,
                        method = "IBCF",
                        parameter = list(method = "Cosine"))

pred <- predict(rec.model, r, type = "ratings")
pred_matrix <- as(pred, "matrix")

# make into a df to visualize and join easier than a matrix
ibcf_preds <- pred_matrix %>% 
  as.data.frame.matrix() %>% 
  rownames_to_column(var = "userId") %>% 
  gather(key = movieId, value = IBCF_rating, -userId)

test_set <- test_set %>% 
 mutate(userId = as.character(userId),
        movieId = as.character(movieId)) %>% 
 select(userId, movieId)

# Join the predictions to the test_set
final_ibcf_predictions <- left_join(test_set, ibcf_preds)

RMSE_IBCF <- RMSE(validation$rating, final_ibcf_predictions$IBCF_rating)

#
# add predictions to ensemble
#
all_model_predictions <- all_model_predictions %>% 
    left_join(final_ibcf_predictions, by = c("userId", "movieId"))

#rm(train_set, test_set, rec.model, pred, pred_matrix, r, ibcf_preds, final_ibcf_predictions)

```


## Custom model

 R = mu + b_i + b_i_time + b_u, where:
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mu = the average of all movie ratings by all users
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b_i = the movie bias, b_i = mu - average rating of this movie by all users
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b_i_time = bias (popularity) of a movie during a given time period.
 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b_u = the user bias, b_u = Y - mu - b_i

```{r eval=TRUE, results="hide"}

#
# R = mu + b_i + b_i_time + b_u where:
#   mu = the average of all movie ratings by all users
#   b_i = the movie bias, b_i = mu - average rating of this movie by all users
#   b_i_time = bias (popularity) of a movie during a given time period.
#   b_u = the user bias, b_u = Y - mu - b_i
#

library(caret)
library(tidyverse)
library(lubridate)

train_set <- edx %>% 
  mutate(userId = as.character(userId),
         movieId = as.character(movieId),
         rating_date = round_date(as_datetime(timestamp), unit = "day"))

test_set <- validation %>%  
  mutate(userId = as.character(userId),
         movieId = as.character(movieId),
         rating_date = round_date(as_datetime(timestamp), unit = "day"))

mu <- mean(train_set$rating)

#
# calculate temporal part of item bias, avg rating of item i at time t
# and add to train_set
#

# build time bins
# bin_size tuned to 2 to give best RMSE
first_rating_ts <- min(train_set$timestamp)
last_rating_ts <- max(train_set$timestamp)
d3 <- last_rating_ts - first_rating_ts
bin_size <- as.double(dweeks(2))
num_bins <- ceiling(d3 / bin_size)

# Get the time bin this rating date falls into
get_bin <- function(d) {
  bin <- ceiling((d - first_rating_ts) / bin_size)
  return(bin)
}

#
# find avg for each movie in an interval and store in matrix
#

# build b_i_time matrix to store the bias
b_i_time_matrix <- matrix(nrow = length(unique(train_set$movieId)), ncol = num_bins)
rownames(b_i_time_matrix) <- unique(train_set$movieId)
colnames(b_i_time_matrix) <- c(1:num_bins)
b_i_time_matrix[,] <- 0

# get the time bin for each rating_date
train_set <- train_set %>% 
  mutate(time_bin = get_bin(timestamp))

# calc b_i_time = the avg rating for each movie during each time bin
movie_time_bias <- train_set %>% 
  group_by(movieId, time_bin) %>% 
  summarise(b_i_time = mean(rating - mu))

# store this bias in the matrix [movieId, time_bin]
for(i in 1:nrow(movie_time_bias)) {
    row <- movie_time_bias[i,]
    r <- row$movieId
    c <- row$time_bin
    b_i_time_matrix[r, c] <- row$b_i_time
}

rm(movie_time_bias, row, c, r, i)
gc()

#
# lookup to find a b_i_time
#
get_b_i_time <- function(m, b) {
  bias <- 0
  for (j in 1:length(m)) {
    bias[j] <- b_i_time_matrix[m, b]
  }
  return(bias)
}


# calculate base movie bias = avg rating of the movie
# lambda manually tuned (9)
lambda1 <- 9
movie_bias <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu) / (n() + lambda1))

# calculate user bias
# lambda manually tuned (3)
lambda2 <- 3
user_bias <- train_set %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu) / (n() + lambda2) )



calc_rating <- function(movieId, time_bin, mu, b_i, b_u, rating_date) {
  
  # base prediction
  pred <- mu + b_i + b_i_time_matrix[movieId, time_bin] + b_u
#  pred <- mu + b_i + b_u

  # if rated before 2003-05-15 then round to whole star
  pred <- ifelse(rating_date < ymd("2003-05-15"), 
                 round(pred),
                 pred)

  # Accruracy is better without considering this  
  #
  # Consider fewer 1/2 star ratings than whole star ratings
  # if pred is "near" to whole star then round to whole star
  # otherwise round to 1/2 star
  #
  # rounding thresholds (.4 and .6) optimized by multiple trials
# 
#   pred <- ifelse(pred - as.integer(pred) < .5,
#                  floor(pred),
#           ifelse(pred - as.integer(pred) > .5,
#                  ceiling(pred),
#           as.integer(pred) + .5 ) )

  # recover extreme predictions
  pred <- if_else(pred < .5, 1, pred)
  pred <- if_else(pred > 5, 5, pred)
  
  return(pred)

}


#
# calculate the predictions 
#
final_custom_predictions <- test_set %>% 
  mutate(time_bin = get_bin(timestamp)) %>% 
  left_join(movie_bias, by="movieId") %>%
  left_join(user_bias, by="userId") %>%
  mutate(custom_pred = calc_rating(movieId, time_bin, mu, b_i, b_u, rating_date)) %>% 
  select(userId, movieId, custom_pred)

# add predictions to ensemble
all_model_predictions <- all_model_predictions %>% 
    left_join(final_custom_predictions, by = c("userId", "movieId"))

RMSE_custom <- RMSE(validation$rating, final_custom_predictions$custom_pred)

rm(final_custom_predictions, movie_bias, test_set, train_set, user_bias)
rm(lambda1, lambda2, mu)
rm(b_i_time_matrix, t_bins, num_bins, rating_levels)
rm(calc_rating, get_b_i_time, get_bin)
gc()

```


## Ensemble Evaluation
```{r}

library(tidyverse)
library(caret)

all_model_predictions <- all_model_predictions %>% 
  select(userId, movieId, rating, custom_pred, rf_pred)

mjb <- all_model_predictions %>% 
  select(-userId, -movieId, -rating) %>% 
  as.matrix()

all_model_predictions$ensemble_pred <- rowMeans(mjb, na.rm = TRUE)

Ensemble_RMSE <- RMSE(validation$rating, all_model_predictions$ensemble_pred)

```